{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9425780",
   "metadata": {},
   "source": [
    "Random forrests\n",
    "\n",
    "Деревья Неоч хорошо работают на новых данных. Поэтому юзают леса\n",
    "\n",
    "Сначала bootstrap dataset создаем\n",
    "\n",
    "1)То есть рандомно берём экземпляры из оригинального датасета (размер получившегося датасета будет такой же как и у оригинального, но один и тот же экземпляр(строка) может повторяться несколько раз в новом датасета)\n",
    "\n",
    "2)Потом выбираем рандомно колонки и тренируем дерево\n",
    "\n",
    "Повторяем 1 и 2 шаги много раз и получим много разных деревьев \n",
    "\n",
    "Когда предсказываем , то прогоняем интересующий нас экземпляр через все деревья, аггрегируем ответы и смотрим за какой класс больше проголосовало (классификация) или среднее берём (регрессия, неточно)\n",
    "\n",
    "Такой подход (бутстрап и агрегация) называется bagging\n",
    "\n",
    "Проверка качества работы леса\n",
    "\n",
    "Где-то 1/3 датасета не участвовала в обучении деревьев (ТК при бутстрапе возможно повторение строк) - out-of-bag dataset\n",
    "\n",
    "Мы прогоняем этот датасет по лесу и подсчитываем ошибку (в случае классификации отношение правильно отгаданных к неправильно, а в случае регрессии ssr или mse наверное)\n",
    "\n",
    "Потом мы можем изменять кол-во фичей выбираемых при построении каждого дерева (например сначала брали 2 фичи, в след раз 3 и тп) и чекаем с каким кол-вом фичей лес лучше работает (обычно берут квадрат фичей и проверяют в бОльшую и меньшую стороны)\n",
    "\n",
    "Как бороться с missing values\n",
    "\n",
    "Если данных нет в обучающей выборке\n",
    "\n",
    "То сначала засовываем среднее или моду (для классификационной колонки) в отсутствующие ячейки\n",
    "\n",
    "Потом мы должны найти наиболее схожие экземпляры с теми в которых у нас отсутствуют данные\n",
    "\n",
    "Строим random forest и прогоняем все экземпляры \n",
    "\n",
    "Находим какие экземпляры попали в те же листья что и экземпляры с отсутствующими значениями \n",
    "\n",
    "Строим proximity matrixes и на основании их вычисляем значение для отсутствующего \n",
    "\n",
    "Потом заново строим леса, прогоняем и тп, пока вычисленные значения не перестанут меняться (не сойдутся)6-7 раз где-то \n",
    "\n",
    "Если нет значения какой-то фичи в экземпляре по которому хотим У узнать, то\n",
    "\n",
    "Для классификационных лесов (для регрессии хз как)\n",
    "\n",
    "Сначала копируем этот экземпляр и ставим У класс 1, во второй 0\n",
    "\n",
    "Вышеуказанным методом определяем значение для отсутствующей фичи \n",
    "\n",
    "Затем оба этих экземпляра прогоняем через лес и считаем по какому из них У был чаще угадан правильно \n",
    "\n",
    "Выбираем тот что чаще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567459f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
