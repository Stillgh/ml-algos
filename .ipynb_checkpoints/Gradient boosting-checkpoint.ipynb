{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502d6ed4",
   "metadata": {},
   "source": [
    "Gradient boost\n",
    "Короч суть в построении деревьев каждое из которых строиться на основании ошибок предыдущих деревьев. Предсказания делаются путем прогона экземпляра по всем деревьям \n",
    "Глубина каждого дерева ограничивается, глубина леса может тоже\n",
    "\n",
    "Regression\n",
    "Loss function - SSR/2, на два делят вроде чтобы производную легче вычислять было\n",
    "Сначала пытается создать лист , а не дерево для предсказания (изначальный лист)\n",
    "Первый guess будет среднее по Y\n",
    "Затем GB строит дерево \n",
    "Сначала определяем ошибку для каждого экземпляра(разницу между target и predictex) - pseudo residual \n",
    "Затем строим дерево пытаясь предсказать не Y, а pseudo residuals (residuals)\n",
    "Теперь обновляем колонку pseudo residuals\n",
    "Для этого прогоняем экземпляр по новому дереву и получаем результат предсказанный (среднее по значениям в листе дерева)\n",
    "Потом берём предсказание изначального листа (среднее по y) и прибавляем к нему значение получившееся после прогона экземпляра по дереву умноженное на learning rate (для борьбы с переобучением нужно) \n",
    "Затем из реального Y для этого экземпляра вычитаем сумму\n",
    "То есть\n",
    "residual для экземпляра = target - (pred из изначального листа + l_rate* pred из дерева)\n",
    "Так по всему датасету прогоняем и вычисляем новые residuals\n",
    "Строим ещё одно дерево которое пытается предсказать новые residuals\n",
    "Теперь вычисляем новые residuals прогоняя экземпляры уже через изначальный лист + первое дерево + второе дерево (результат каждого дерево умножаем на learning rate)\n",
    "\n",
    "Каждый раз pseudo residuals будут уменьшаться (значит мы в верном направлении идём)\n",
    "\n",
    "Короч добавляем таким же образом новые деревья пока либо не достигнем максимального колв-ва деревьев которое выбрали, либо когда добавление новых деревьев перестанет значительно уменьшать значения residuals\n",
    "\n",
    "Параметры - \n",
    "Макс кол-во листьев в дереве обычно от 8 до 32 ставят\n",
    "Макс кол-во деревьев \n",
    "\n",
    "Classifcation\n",
    "Также создаём изначальный лист (initial prediction), в регрессии это было среднее по Y, в классификации это log(odds), те у 4х челов Y равен классу А, у 2х классу B - log(4/2)\n",
    "Затем с помощью logistic функции (сигмовидной) конвертим значение в вероятность\n",
    "В нашем случае получили 0.7 \n",
    "То есть наш лист для всех выдает вероятность 0.7, что экземпляр относится к классу А\n",
    "Выбираем threshold (0.5 обычно)\n",
    "Те если predicted probability >= 0.5, то класс А, если нет, то класс Б\n",
    "Тк наш лист выдает 0.7, то мы все экземпляры относим к классу А\n",
    "\n",
    "Затем вычисляем residuals (чтобы понять насколько плохо наш лист перформит)\n",
    "Берём реальные Y у экземпляров (если экземпляр к классу А относится то Y = 1 у него, если к классу Б, то 0 \n",
    "И для каждого экземпляра residual будет равен observed(1 или 0 в зависимости от класса) минус predicted (0.7)\n",
    "\n",
    "Теперь строим дерево для предугадывания residuals\n",
    "Построили дерево ( в листах соотвно получили 1 или больше residuals (ТК мы их угадывать учились))\n",
    "Теперь должны трансформировать эти предсказания в листах дерева, ТК дерево было обучено на residuals, которые были выведены из вероятностей (от 1 или 0 отнимали 0.7), а предсказания имеют природу log(odds). То есть мы не можем сложить все значения в каком-то листе и найти среднее как в случае с регрессией\n",
    " Формула для трансформации\n",
    "Сумма residuals (то что в листе дерева) деленная на сумму предыдущая вероятность (0.7 в нашем случае) умноженная на 1- предыдущая вероятность \n",
    "Сделали трансформацию и получили конечные значения которые будет выдавать дерево когда через него прогонят экземпляр \n",
    "То есть сначала у нас в листьях деревьев было 1 или больше residuals на которых это дерево обучили, а после трансформации в каждом листе по новому значению (аналог среднего в деревьях регрессии)\n",
    "\n",
    "Теперь вычисляем новое предсказание - берем изначальный лист (он log(4/2) предсказывает прибавляем learning rate умноженный на предсказание построенного дерева и конвертим его с помощью logistic function\n",
    "\n",
    "И так вычисляем новую predicted probability для каждого экземпляра\n",
    "И вычисляем новые residuals (obzerved probability (1 или 0) минус predicted probability (уже не 0.7 для каждого, а для каждого своя, ТК эту новую probability мы вычисляем с помощью изначального листа и дерева через которые прогоняем экземпляры)\n",
    "Строим новое дерево , также трансформируем значения в его листьях\n",
    "И добавляем это дерево в нашу модель\n",
    "Теперь как делаем предсказания с нашей моделью \n",
    "Берём экземпляр по которому нужно У определить\n",
    "И прогоняем его через модель (изначальный лист и все деревья построенные), полученную log(odds) превращаем в probability ( с пом logistic function), сравниваем с трешхолдом и даём ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833dcf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
